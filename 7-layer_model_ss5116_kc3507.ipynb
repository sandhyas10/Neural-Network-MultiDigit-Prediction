{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 7-layer model\n",
    "This notebook shows a 7-layer model with INPUT -> [CONV -> RELU -> MAXPOOL-> BATCHNORM -> DROPOUT]X7 -> [FC -> RELU]X2 -> OUTPUT\n",
    "Data-> (54,54,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please change file name and location below to the name and location of the file you would like to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading data files\n",
    "data = h5py.File('data/digits_54_54_3.h5','r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading training data\n",
    "X_train = data['train_dataset'][:]\n",
    "y_train = data['train_labels'][:]\n",
    "X_val = data['valid_dataset'][:]\n",
    "y_val = data['valid_labels'][:]\n",
    "X_test=data['test_dataset'][:]\n",
    "y_test=data['test_labels'][:]\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (29401, 54, 54, 3) (29401, 5)\n",
      "Validation set (4000, 54, 54, 3) (4000, 5)\n",
      "Test set (13068, 54, 54, 3) (13068, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('Validation set', X_val.shape, y_val.shape)\n",
    "print('Test set', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please change file name and location below to the name and location of the file you would like to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading extra data\n",
    "data = h5py.File('data/digits_54_54_3.h5','r')\n",
    "X_extra=data['extra_dataset'][:]\n",
    "y_extra=data['extra_labels'][:]\n",
    "X_val_extra=data['valid_extra_dataset'][:]\n",
    "y_val_extra=data['valid_extra_labels'][:]\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting 20000 samples from extra\n",
    "X_extra1=X_extra[0:20000]\n",
    "y_extra1=y_extra[0:20000]\n",
    "X_val_extra1=X_val_extra[0:2000]\n",
    "y_val_extra1=y_val_extra[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (49401, 54, 54, 3) (49401, 5)\n",
      "Validation set (6000, 54, 54, 3) (6000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating the extra data with training\n",
    "X_train = np.concatenate([X_train,X_extra1])\n",
    "y_train = np.concatenate([y_train,y_extra1])\n",
    "X_val = np.concatenate([X_val,X_val_extra1])\n",
    "y_val = np.concatenate([y_val,y_val_extra1])\n",
    "print('Train set', X_train.shape, y_train.shape)\n",
    "print('Validation set', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finding number of channels, labels and digits\n",
    "num_channels=X_train.shape[3]\n",
    "num_digits,num_labels=y_train.shape[1],len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional layer and Fully-connected layer definition\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "class conv_layer(object):\n",
    "    def __init__(self, input_x, in_channel, out_channel, kernel_shape, pooling,rand_seed,index=0,first=False):\n",
    "        \"\"\"\n",
    "        :param input_x: The input of the conv layer. Should be a 4D array like (batch_num, img_len, img_len, channel_num)\n",
    "        :param in_channel: The 4-th demension (channel number) of input matrix. For example, in_channel=3 means the input contains 3 channels.\n",
    "        :param out_channel: The 4-th demension (channel number) of output matrix. For example, out_channel=5 means the output contains 5 channels (feature maps).\n",
    "        :param kernel_shape: the shape of the kernel. For example, kernal_shape = 3 means you have a 3*3 kernel.\n",
    "        :param rand_seed: An integer that presents the random seed used to generate the initial parameter value.\n",
    "        :param index: The index of the layer. It is used for naming only.\n",
    "        \"\"\"\n",
    "             \n",
    "        assert len(input_x.shape) == 4 and input_x.shape[1] == input_x.shape[2] and input_x.shape[3] == in_channel\n",
    "\n",
    "        with tf.variable_scope('conv_layer_%d' % index):\n",
    "            with tf.name_scope('conv_kernel'):\n",
    "                w_shape = [kernel_shape, kernel_shape, in_channel, out_channel]\n",
    "                weight = tf.get_variable(name='conv_kernel_%d' % index, shape=w_shape,\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "                self.weight = weight\n",
    "\n",
    "            with tf.variable_scope('conv_bias'):\n",
    "                b_shape = [out_channel]\n",
    "                bias = tf.get_variable(name='conv_bias_%d' % index, shape=b_shape,\n",
    "                                       initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "                self.bias = bias\n",
    "\n",
    "            conv_out = tf.nn.conv2d(input_x, weight, strides=[1, 2, 2, 1],padding=\"SAME\")\n",
    "            conv_out = tf.nn.relu(conv_out+bias)\n",
    "            #Pooling between alternate layers                \n",
    "            if pooling==True:\n",
    "                conv_out = tf.nn.max_pool(conv_out, [1, 2, 2, 1], [1, 2, 2, 1],'SAME')\n",
    "            conv_out=tf.layers.batch_normalization(conv_out,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True)\n",
    "\n",
    "            self.cell_out = conv_out\n",
    "\n",
    "            tf.summary.histogram('conv_layer/{}/kernel'.format(index), weight)\n",
    "            tf.summary.histogram('conv_layer/{}/bias'.format(index), bias)\n",
    "\n",
    "    def output(self):\n",
    "        return self.cell_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class fc_layer(object):\n",
    "    def __init__(self, input_x, in_size, out_size, rand_seed, activation_function=None,relu=False, index=0):\n",
    "        \"\"\"\n",
    "        :param input_x: The input of the FC layer. It should be a flatten vector.\n",
    "        :param in_size: The length of input vector.\n",
    "        :param out_size: The length of output vector.\n",
    "        :param rand_seed: An integer that presents the random seed used to generate the initial parameter value.\n",
    "        :param keep_prob: The probability of dropout. Default set by 1.0 (no drop-out applied)\n",
    "        :param activation_function: The activation function for the output. Default set to None.\n",
    "        :param index: The index of the layer. It is used for naming only.\n",
    "\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('fc_layer_%d' % index):\n",
    "            with tf.name_scope('fc_kernel'):\n",
    "                w_shape = [in_size, out_size]\n",
    "                weight = tf.get_variable(name='fc_kernel_%d' % index, shape=w_shape,\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "                self.weight = weight\n",
    "\n",
    "            with tf.variable_scope('fc_kernel'):\n",
    "                b_shape = [out_size]\n",
    "                bias = tf.get_variable(name='fc_bias_%d' % index, shape=b_shape,\n",
    "                                       initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "                self.bias = bias\n",
    "\n",
    "            cell_out = tf.add(tf.matmul(input_x, weight), bias)\n",
    "            if relu is True:\n",
    "                cell_out = tf.nn.relu(cell_out+bias)\n",
    "            \n",
    "            self.cell_out = cell_out\n",
    "\n",
    "            tf.summary.histogram('fc_layer/{}/kernel'.format(index), weight)\n",
    "            tf.summary.histogram('fc_layer/{}/bias'.format(index), bias)\n",
    "\n",
    "    def output(self):\n",
    "        return self.cell_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEfinition of 7-layer net\n",
    "def LeNet(input_x, input_y, nfilter_1, nfilter_2,nfilter_3, nfilter_4,nfilter_5,nfilter_6,nfilter_7,nfilter_8,\n",
    "        filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8,img_len=54, num_channels=3, l2_norm=0.01, seed=235):\n",
    "\n",
    "\n",
    "    # convolutional layer1 \n",
    "\n",
    "    conv_layer_0 = conv_layer(input_x=input_x,\n",
    "                              in_channel=num_channels,\n",
    "                              out_channel=nfilter_1,\n",
    "                              kernel_shape=filter_1,\n",
    "                              pooling=False,\n",
    "                              rand_seed=seed,first=True, index=0)\n",
    "   # convolutional layer2\n",
    "    conv_layer_1 = conv_layer(input_x=conv_layer_0.output(),\n",
    "                              in_channel=nfilter_1,\n",
    "                              out_channel=nfilter_2,\n",
    "                              kernel_shape=filter_2,\n",
    "                              pooling=True,\n",
    "                              rand_seed=seed,first=False,index=1)\n",
    "\n",
    "    # convolutional layer3\n",
    "    conv_layer_2 = conv_layer(input_x=conv_layer_1.output(),\n",
    "                              in_channel=nfilter_2,\n",
    "                              out_channel=nfilter_3,\n",
    "                              kernel_shape=filter_3,\n",
    "                              pooling=False,\n",
    "                              rand_seed=seed,first=False,index=2)\n",
    "    #dropout layer 1\n",
    "    dropout_layer_0 = tf.nn.dropout(conv_layer_2.output(), keep_prob=0.9)\n",
    "    \n",
    "   # convolutional layer4\n",
    "    conv_layer_3 = conv_layer(input_x=conv_layer_2.output(),\n",
    "                              in_channel=nfilter_3,\n",
    "                              out_channel=nfilter_4,\n",
    "                              kernel_shape=filter_4,\n",
    "                              pooling=False,\n",
    "                              rand_seed=seed,first=False,index=3)\n",
    "    # convolutional layer5\n",
    "    conv_layer_4 = conv_layer(input_x=conv_layer_3.output(),\n",
    "                              in_channel=nfilter_4,\n",
    "                              out_channel=nfilter_5,\n",
    "                              kernel_shape=filter_5,\n",
    "                              pooling=False,\n",
    "                              rand_seed=seed,first=False,index=4)\n",
    "    # convolutional layer6\n",
    "    conv_layer_5 = conv_layer(input_x=conv_layer_4.output(),\n",
    "                              in_channel=nfilter_5,\n",
    "                              out_channel=nfilter_6,\n",
    "                              kernel_shape=filter_6,\n",
    "                              pooling=True,\n",
    "                              rand_seed=seed,first=False,index=5)\n",
    "     #dropout layer 2\n",
    "    dropout_layer_1 = tf.nn.dropout(conv_layer_5.output(), keep_prob=0.9)\n",
    "    # convolutional layer7\n",
    "    conv_layer_6 = conv_layer(input_x=conv_layer_5.output(),\n",
    "                              in_channel=nfilter_6,\n",
    "                              out_channel=nfilter_7,\n",
    "                              kernel_shape=filter_7,\n",
    "                              pooling=True,\n",
    "                              rand_seed=seed,first=False,index=6)\n",
    "    \n",
    "\n",
    "    \n",
    "                          \n",
    "\n",
    "    # flatten\n",
    "    pool_shape = conv_layer_6.output().get_shape()\n",
    "    img_vector_length = pool_shape[1].value * pool_shape[2].value * pool_shape[3].value\n",
    "    flatten = tf.reshape(conv_layer_6.output(), shape=[-1, img_vector_length])\n",
    "\n",
    "    \n",
    "\n",
    "     # fc layer 1\n",
    "    fc_layer_0 = fc_layer(input_x=flatten,\n",
    "                          in_size=img_vector_length,\n",
    "                          out_size=fclayer1_size,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,\n",
    "                          index=0,\n",
    "                          relu=True)\n",
    "     #dropout layer 3\n",
    "    dropout_layer_2 = tf.nn.dropout(fc_layer_0.output(), keep_prob=0.9)\n",
    "    \n",
    "     # fc layer 2\n",
    "    fc_layer_1 = fc_layer(input_x=dropout_layer_2,\n",
    "                          in_size=fclayer1_size,\n",
    "                          out_size=fclayer2_size,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=None,\n",
    "                          index=1,\n",
    "                          relu=False)\n",
    "   #dropout layer 4\n",
    "    dropout_layer_3 = tf.nn.dropout(fc_layer_1.output(), keep_prob=0.9)\n",
    "    \n",
    "    #Output -> softmax functions\n",
    "    logits_1=fc_layer(input_x=dropout_layer_3,\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=2,\n",
    "                          relu=False)\n",
    "    logits_2=fc_layer(input_x=dropout_layer_3,\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=3,\n",
    "                          relu=False)\n",
    "    logits_3=fc_layer(input_x=dropout_layer_3,\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=4,\n",
    "                          relu=False)\n",
    "    logits_4=fc_layer(input_x=dropout_layer_3,\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=5,\n",
    "                          relu=False)\n",
    "    logits_5=fc_layer(input_x=dropout_layer_3,\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=6,\n",
    "                          relu=False)\n",
    "        \n",
    "    \n",
    "    y_pred = tf.stack([logits_1.output(), logits_2.output(), logits_3.output(), logits_4.output(), logits_5.output()])\n",
    "    y_pred = tf.transpose(tf.argmax(y_pred, axis=2))  \n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "       \n",
    "        loss1 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_1.output(), labels= input_y[:,0]))\n",
    "        loss2 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_2.output(), labels= input_y[:,1]))\n",
    "        loss3 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_3.output(), labels= input_y[:,2]))\n",
    "        loss4 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_4.output(), labels=input_y[:,3]))\n",
    "        loss5 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_5.output(), labels=input_y[:,4]))\n",
    "\n",
    "        loss = loss1 + loss2 + loss3 + loss4 + loss5 \n",
    "        tf.summary.scalar('loss', loss)\n",
    "        print(\"Iteration done\")\n",
    "\n",
    "    return y_pred,loss\n",
    "\n",
    "   \n",
    "\n",
    "def train_step(loss, learning_rate=1e-3):\n",
    "    \n",
    "    #Optimizer\n",
    "    with tf.name_scope('train_step'):\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate=1e-3\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        step = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    return step\n",
    "\n",
    "def evaluate(predictions, labels):\n",
    "    with tf.name_scope('accuracy'):\n",
    "            correct_prediction = tf.equal(predictions, labels)\n",
    "            correct_prediction=tf.cast(correct_prediction, tf.float32)\n",
    "            correct_prediction=tf.reduce_min(correct_prediction,1)\n",
    "            acc=tf.reduce_mean(correct_prediction)\n",
    "            tf.summary.scalar('accuracy', acc)\n",
    "            acc=acc*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training function for the LeNet model\n",
    "def training(X_train, y_train, X_val, y_val,X_test,y_test, nfilter_1, nfilter_2,nfilter_3, nfilter_4,nfilter_5,nfilter_6,nfilter_7,nfilter_8,filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8,img_len=32, num_channels=1, l2_norm=0.01, \n",
    "             seed=235,\n",
    "             learning_rate=1e-2,\n",
    "             epoch=20,\n",
    "             batch_size=245,\n",
    "             verbose=False,\n",
    "             pre_trained_model=None):\n",
    "    best_acc_li=[]\n",
    "    all_acc=[]\n",
    "    \n",
    "\n",
    "    with tf.name_scope('inputs'):\n",
    "        xs = tf.placeholder(shape=[None, 54, 54, 3], dtype=tf.float32)\n",
    "        ys = tf.placeholder(shape=[None,5 ], dtype=tf.int64)\n",
    "        \n",
    "\n",
    "    output, loss = LeNet(xs, ys, nfilter_1, nfilter_2,nfilter_3, nfilter_4,nfilter_5,nfilter_6,nfilter_7,nfilter_8,\n",
    "        filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8, img_len=54, num_channels=3, l2_norm=0.01, seed=235)\n",
    "    iters = int(X_train.shape[0] / batch_size)\n",
    "    print('number of batches for training: {}'.format(iters))\n",
    "\n",
    "    step = train_step(loss)\n",
    "    eve = evaluate(output,ys)\n",
    "\n",
    "    iter_total = 0\n",
    "    best_acc = 0\n",
    "    cur_model_name = 'lenet_{}'.format(int(time.time()))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        merge = tf.summary.merge_all()\n",
    "\n",
    "        writer = tf.summary.FileWriter(\"log/{}\".format(cur_model_name), sess.graph)\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        if pre_trained_model is not None:\n",
    "            try:\n",
    "                print(\"Load the model from: {}\".format(pre_trained_model))\n",
    "                saver.restore(sess, 'model/{}'.format(pre_trained_model))\n",
    "            except Exception:\n",
    "                print(\"Load model Failed!\")\n",
    "                pass\n",
    "\n",
    "        for epc in range(epoch):\n",
    "            print(\"epoch {} \".format(epc + 1))\n",
    "\n",
    "            for itr in range(iters):\n",
    "                iter_total += 1\n",
    "\n",
    "                training_batch_x = X_train[itr * batch_size: (1 + itr) * batch_size]\n",
    "                training_batch_y = y_train[itr * batch_size: (1 + itr) * batch_size]\n",
    "\n",
    "                _, cur_loss = sess.run([step, loss], feed_dict={xs: training_batch_x, ys: training_batch_y})\n",
    "              \n",
    "                if iter_total % 500 == 0:\n",
    "                   \n",
    "                    valid_acc, merge_result = sess.run([eve, merge], feed_dict={xs: X_val, ys: y_val})\n",
    "                    print(valid_acc)\n",
    "                    if verbose:\n",
    "                        print('{}/{} loss: {} validation accuracy : {}%'.format(\n",
    "                            batch_size * (itr + 1),\n",
    "                            X_train.shape[0],\n",
    "                            cur_loss,\n",
    "                            valid_acc))\n",
    "                    all_acc.append(valid_acc)\n",
    "                    # save the merge result summary\n",
    "                    writer.add_summary(merge_result, iter_total)\n",
    "\n",
    "                    # when achieve the best validation accuracy, we store the model paramters\n",
    "                    if valid_acc > best_acc:\n",
    "                        print('Best validation accuracy! iteration:{} accuracy: {}%'.format(iter_total, valid_acc))\n",
    "                        best_acc = valid_acc\n",
    "                        best_acc_li.append(best_acc)\n",
    "                        saver.save(sess, 'model/{}'.format(cur_model_name))\n",
    "                        \n",
    "                    test_acc = sess.run(eve, feed_dict={xs: X_test, ys: y_test})\n",
    "                    print('Test Accuracy : {}'.format(test_acc))\n",
    "\n",
    "        test_acc = sess.run(eve, feed_dict={xs: X_test, ys: y_test})\n",
    "        print('Test Accuracy : {}'.format(test_acc))\n",
    "    print(\"Traning ends. The best valid accuracy is {}. Model named {}.\".format(best_acc, cur_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional layer units\n",
    "filter_1 = filter_2 = filter_3 = filter_4=filter_5=filter_6=filter_7=filter_8 = 5        \n",
    "nfilter_1 = 48\n",
    "nfilter_2 = 64                 \n",
    "nfilter_3 = 128\n",
    "nfilter_4 = 160   \n",
    "nfilter_5=nfilter_6=nfilter_7=nfilter_8=192\n",
    "# Fully connected layer units\n",
    "fclayer1_size = fclayer2_size = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 27, 27, 48)\n",
      "(?, 7, 7, 64)\n",
      "(?, 4, 4, 128)\n",
      "WARNING:tensorflow:From <ipython-input-9-e82526597fa3>:155: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "(?, 5)\n",
      "(?, 11)\n",
      "(?,)\n",
      "Iteration done\n",
      "Done LeNet training\n",
      "Tensor(\"transpose:0\", shape=(?, 5), dtype=int64)\n",
      "number of batches for training: 98\n",
      "Tensor(\"accuracy/Min:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"accuracy/mul:0\", shape=(), dtype=float32)\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "epoch 3 \n",
      "epoch 4 \n",
      "epoch 5 \n",
      "epoch 6 \n",
      "2.15\n",
      "Best validation accuracy! iteration:500 accuracy: 2.1500000953674316%\n",
      "Test Accuracy : 2.5405571460723877\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "epoch 9 \n",
      "epoch 10 \n",
      "epoch 11 \n",
      "28.5\n",
      "Best validation accuracy! iteration:1000 accuracy: 28.500001907348633%\n",
      "Test Accuracy : 30.677995681762695\n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "epoch 15 \n",
      "epoch 16 \n",
      "52.4\n",
      "Best validation accuracy! iteration:1500 accuracy: 52.40000534057617%\n",
      "Test Accuracy : 52.112030029296875\n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "epoch 21 \n",
      "58.775\n",
      "Best validation accuracy! iteration:2000 accuracy: 58.77500915527344%\n",
      "Test Accuracy : 57.262020111083984\n",
      "epoch 22 \n",
      "epoch 23 \n",
      "epoch 24 \n",
      "epoch 25 \n",
      "epoch 26 \n",
      "62.65\n",
      "Best validation accuracy! iteration:2500 accuracy: 62.650001525878906%\n",
      "Test Accuracy : 60.76676940917969\n",
      "epoch 27 \n",
      "epoch 28 \n",
      "epoch 29 \n",
      "epoch 30 \n",
      "epoch 31 \n",
      "63.875\n",
      "Best validation accuracy! iteration:3000 accuracy: 63.87500762939453%\n",
      "Test Accuracy : 61.76921081542969\n",
      "epoch 32 \n",
      "epoch 33 \n",
      "epoch 34 \n",
      "epoch 35 \n",
      "epoch 36 \n",
      "64.725\n",
      "Best validation accuracy! iteration:3500 accuracy: 64.72500610351562%\n",
      "Test Accuracy : 62.480873107910156\n",
      "epoch 37 \n",
      "epoch 38 \n",
      "epoch 39 \n",
      "epoch 40 \n",
      "epoch 41 \n",
      "63.6\n",
      "Test Accuracy : 60.23875427246094\n",
      "epoch 42 \n",
      "epoch 43 \n",
      "epoch 44 \n",
      "epoch 45 \n",
      "epoch 46 \n",
      "64.5\n",
      "Test Accuracy : 60.7973747253418\n",
      "epoch 47 \n",
      "epoch 48 \n",
      "epoch 49 \n",
      "epoch 50 \n",
      "epoch 51 \n",
      "epoch 52 \n",
      "63.825\n",
      "Test Accuracy : 61.378944396972656\n",
      "epoch 53 \n",
      "epoch 54 \n",
      "epoch 55 \n",
      "epoch 56 \n",
      "epoch 57 \n",
      "67.325\n",
      "Best validation accuracy! iteration:5500 accuracy: 67.32500457763672%\n",
      "Test Accuracy : 63.399147033691406\n",
      "epoch 58 \n",
      "epoch 59 \n",
      "epoch 60 \n",
      "epoch 61 \n",
      "epoch 62 \n",
      "67.35\n",
      "Best validation accuracy! iteration:6000 accuracy: 67.3499984741211%\n",
      "Test Accuracy : 64.18733215332031\n",
      "epoch 63 \n",
      "epoch 64 \n",
      "epoch 65 \n",
      "epoch 66 \n",
      "epoch 67 \n",
      "66.6\n",
      "Test Accuracy : 63.6669807434082\n",
      "epoch 68 \n",
      "epoch 69 \n",
      "epoch 70 \n",
      "epoch 71 \n",
      "epoch 72 \n",
      "66.65\n",
      "Test Accuracy : 64.54698944091797\n",
      "epoch 73 \n",
      "epoch 74 \n",
      "epoch 75 \n",
      "epoch 76 \n",
      "epoch 77 \n",
      "67.175\n",
      "Test Accuracy : 63.8353271484375\n",
      "epoch 78 \n",
      "epoch 79 \n",
      "epoch 80 \n",
      "epoch 81 \n",
      "epoch 82 \n",
      "66.575\n",
      "Test Accuracy : 63.904197692871094\n",
      "epoch 83 \n",
      "epoch 84 \n",
      "epoch 85 \n",
      "epoch 86 \n",
      "epoch 87 \n",
      "67.3\n",
      "Test Accuracy : 64.06489562988281\n",
      "epoch 88 \n",
      "epoch 89 \n",
      "epoch 90 \n",
      "epoch 91 \n",
      "epoch 92 \n",
      "66.575\n",
      "Test Accuracy : 64.34038543701172\n",
      "epoch 93 \n",
      "epoch 94 \n",
      "epoch 95 \n",
      "epoch 96 \n",
      "epoch 97 \n",
      "67.725\n",
      "Best validation accuracy! iteration:9500 accuracy: 67.72500610351562%\n",
      "Test Accuracy : 65.09795379638672\n",
      "epoch 98 \n",
      "epoch 99 \n",
      "epoch 100 \n",
      "epoch 101 \n",
      "epoch 102 \n",
      "epoch 103 \n",
      "67.1\n",
      "Test Accuracy : 63.90420150756836\n",
      "epoch 104 \n",
      "epoch 105 \n",
      "epoch 106 \n",
      "epoch 107 \n",
      "epoch 108 \n",
      "67.4\n",
      "Test Accuracy : 64.96021270751953\n",
      "epoch 109 \n",
      "epoch 110 \n",
      "epoch 111 \n",
      "epoch 112 \n",
      "epoch 113 \n",
      "68.5\n",
      "Best validation accuracy! iteration:11000 accuracy: 68.5%\n",
      "Test Accuracy : 65.17447662353516\n",
      "epoch 114 \n",
      "epoch 115 \n",
      "epoch 116 \n",
      "epoch 117 \n",
      "epoch 118 \n",
      "68.4\n",
      "Test Accuracy : 65.49588012695312\n",
      "epoch 119 \n",
      "epoch 120 \n",
      "epoch 121 \n",
      "epoch 122 \n",
      "epoch 123 \n",
      "67.0\n",
      "Test Accuracy : 64.8836898803711\n",
      "epoch 124 \n",
      "epoch 125 \n",
      "epoch 126 \n",
      "epoch 127 \n",
      "epoch 128 \n",
      "68.275\n",
      "Test Accuracy : 65.3734359741211\n",
      "epoch 129 \n",
      "epoch 130 \n",
      "epoch 131 \n",
      "epoch 132 \n",
      "epoch 133 \n",
      "68.4\n",
      "Test Accuracy : 65.20509338378906\n",
      "epoch 134 \n",
      "epoch 135 \n",
      "epoch 136 \n",
      "epoch 137 \n",
      "epoch 138 \n",
      "68.6\n",
      "Best validation accuracy! iteration:13500 accuracy: 68.5999984741211%\n",
      "Test Accuracy : 65.99327087402344\n",
      "epoch 139 \n",
      "epoch 140 \n",
      "epoch 141 \n",
      "epoch 142 \n",
      "epoch 143 \n",
      "67.875\n",
      "Test Accuracy : 65.22039031982422\n",
      "epoch 144 \n",
      "epoch 145 \n",
      "epoch 146 \n",
      "epoch 147 \n",
      "epoch 148 \n",
      "68.825\n",
      "Best validation accuracy! iteration:14500 accuracy: 68.82500457763672%\n",
      "Test Accuracy : 65.6183090209961\n",
      "epoch 149 \n",
      "epoch 150 \n",
      "epoch 151 \n",
      "epoch 152 \n",
      "epoch 153 \n",
      "epoch 154 \n",
      "68.725\n",
      "Test Accuracy : 64.71533966064453\n",
      "epoch 155 \n",
      "epoch 156 \n",
      "epoch 157 \n",
      "epoch 158 \n",
      "epoch 159 \n",
      "69.925\n",
      "Best validation accuracy! iteration:15500 accuracy: 69.92500305175781%\n",
      "Test Accuracy : 65.7407455444336\n",
      "epoch 160 \n",
      "epoch 161 \n",
      "epoch 162 \n",
      "epoch 163 \n",
      "epoch 164 \n",
      "69.575\n",
      "Test Accuracy : 66.12335968017578\n",
      "epoch 165 \n",
      "epoch 166 \n",
      "epoch 167 \n",
      "epoch 168 \n",
      "epoch 169 \n",
      "69.175\n",
      "Test Accuracy : 65.48822784423828\n",
      "epoch 170 \n",
      "epoch 171 \n",
      "epoch 172 \n",
      "epoch 173 \n",
      "epoch 174 \n",
      "68.675\n",
      "Test Accuracy : 65.87084197998047\n",
      "epoch 175 \n",
      "epoch 176 \n",
      "epoch 177 \n",
      "epoch 178 \n",
      "epoch 179 \n",
      "68.475\n",
      "Test Accuracy : 64.89134216308594\n",
      "epoch 180 \n",
      "epoch 181 \n",
      "epoch 182 \n",
      "epoch 183 \n",
      "epoch 184 \n",
      "68.625\n",
      "Test Accuracy : 65.56474304199219\n",
      "epoch 185 \n",
      "epoch 186 \n",
      "epoch 187 \n",
      "epoch 188 \n",
      "epoch 189 \n",
      "69.65\n",
      "Test Accuracy : 65.97796630859375\n",
      "epoch 190 \n",
      "epoch 191 \n",
      "epoch 192 \n",
      "epoch 193 \n",
      "epoch 194 \n",
      "68.4\n",
      "Test Accuracy : 65.6183090209961\n",
      "epoch 195 \n",
      "epoch 196 \n",
      "epoch 197 \n",
      "epoch 198 \n",
      "epoch 199 \n",
      "68.2\n",
      "Test Accuracy : 65.74075317382812\n",
      "epoch 200 \n",
      "Traning ends. The best valid accuracy is 69.92500305175781. Model named lenet_1513582249.\n"
     ]
    }
   ],
   "source": [
    "#Callingthe training function\n",
    "temp=time.time()\n",
    "training(X_train, y_train, X_val, y_val, X_test,y_test, nfilter_1, nfilter_2,nfilter_3, nfilter_4,nfilter_5,nfilter_6,nfilter_7,nfilter_8,filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8,img_len=54, num_channels=3, l2_norm=0.01, \n",
    "             seed=235,\n",
    "             learning_rate=1e-3,\n",
    "             epoch=200,\n",
    "             batch_size=300,\n",
    "             verbose=False,\n",
    "             pre_trained_model=None)\n",
    "temp1=time.time() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2978.9965176582336"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time=temp1-temp\n",
    "print(\"Total time taken is {}\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
