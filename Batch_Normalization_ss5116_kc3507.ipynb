{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BATCH NORMALIZATION\n",
    "This notebook shows a CNN model with [[CONV -> RELU -> MAXPOOL -> BATCHNORM] X 3  -> [FC Layer -> Dropout]X2 \n",
    "\n",
    "\n",
    "Data-> (54,54,3) for 5 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change file name and location below to the name and location of the file you would like to load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading data files\n",
    "data = h5py.File('data/digits_54_54_3.h5','r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading training data\n",
    "X_train=data['train_dataset'][:]\n",
    "y_train=data['train_labels'][:]\n",
    "X_val=data['valid_dataset'][:]\n",
    "y_val=data['valid_labels'][:]\n",
    "X_test=data['test_dataset'][:]\n",
    "y_test=data['test_labels'][:]\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (29401, 54, 54, 3) (29401, 5)\n",
      "Validation set (4000, 54, 54, 3) (4000, 5)\n",
      "Test set (13068, 54, 54, 3) (13068, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('Validation set', X_val.shape, y_val.shape)\n",
    "print('Test set', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading extra data\n",
    "data = h5py.File('data/digits_54_54_3.h5','r')\n",
    "X_extra=data['extra_dataset'][:]\n",
    "y_extra=data['extra_labels'][:]\n",
    "X_val_extra=data['valid_extra_dataset'][:]\n",
    "y_val_extra=data['valid_extra_labels'][:]\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting 20000 samples from extra\n",
    "X_extra1=X_extra[0:20000]\n",
    "y_extra1=y_extra[0:20000]\n",
    "X_val_extra1=X_val_extra[0:2000]\n",
    "y_val_extra1=y_val_extra[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (49401, 54, 54, 3) (49401, 5)\n",
      "Validation set (6000, 54, 54, 3) (6000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating the extra data with training\n",
    "X_train = np.concatenate([X_train,X_extra1])\n",
    "y_train = np.concatenate([y_train,y_extra1])\n",
    "X_val = np.concatenate([X_val,X_val_extra1])\n",
    "y_val = np.concatenate([y_val,y_val_extra1])\n",
    "print('Train set', X_train.shape, y_train.shape)\n",
    "print('Validation set', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finding number of channels, labels and digits\n",
    "num_channels=X_train.shape[3]\n",
    "num_digits=y_train.shape[1]\n",
    "num_labels=len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of conv and FC layer \n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "class conv_layer(object):\n",
    "    def __init__(self, input_x, in_channel, out_channel, kernel_shape, rand_seed,pooling,index=0,first=False):\n",
    "        \"\"\"\n",
    "        :param input_x: The input of the conv layer. Should be a 4D array like (batch_num, img_len, img_len, channel_num)\n",
    "        :param in_channel: The 4-th demension (channel number) of input matrix. For example, in_channel=3 means the input contains 3 channels.\n",
    "        :param out_channel: The 4-th demension (channel number) of output matrix. For example, out_channel=5 means the output contains 5 channels (feature maps).\n",
    "        :param kernel_shape: the shape of the kernel. For example, kernal_shape = 3 means you have a 3*3 kernel.\n",
    "        :param rand_seed: An integer that presents the random seed used to generate the initial parameter value.\n",
    "        :param index: The index of the layer. It is used for naming only.\n",
    "        \"\"\"\n",
    "             \n",
    "        assert len(input_x.shape) == 4 and input_x.shape[1] == input_x.shape[2] and input_x.shape[3] == in_channel\n",
    "\n",
    "        with tf.variable_scope('conv_layer_%d' % index):\n",
    "            with tf.name_scope('conv_kernel'):\n",
    "                w_shape = [kernel_shape, kernel_shape, in_channel, out_channel]\n",
    "                weight = tf.get_variable(name='conv_kernel_%d' % index, shape=w_shape,\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "                self.weight = weight\n",
    "\n",
    "            with tf.variable_scope('conv_bias'):\n",
    "                b_shape = [out_channel]\n",
    "                bias = tf.get_variable(name='conv_bias_%d' % index, shape=b_shape,\n",
    "                                       initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "                self.bias = bias\n",
    "\n",
    "            \n",
    "            conv_out = tf.nn.conv2d(input_x, weight, strides=[1, 2, 2, 1],padding=\"SAME\")\n",
    "            conv_out = tf.nn.relu(conv_out+bias)\n",
    "                            \n",
    "           \n",
    "            \n",
    "            conv_out = tf.nn.max_pool(conv_out, [1, 2, 2, 1], [1, 2, 2, 1],'SAME')\n",
    "            conv_out=tf.layers.batch_normalization(conv_out,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True)\n",
    "            \n",
    "\n",
    "            self.cell_out = conv_out\n",
    "\n",
    "           \n",
    "    def output(self):\n",
    "        return self.cell_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class fc_layer(object):\n",
    "    def __init__(self, input_x, in_size, out_size, rand_seed, activation_function=None,relu=False, index=0):\n",
    "        \"\"\"\n",
    "        :param input_x: The input of the FC layer. It should be a flatten vector.\n",
    "        :param in_size: The length of input vector.\n",
    "        :param out_size: The length of output vector.\n",
    "        :param rand_seed: An integer that presents the random seed used to generate the initial parameter value.\n",
    "        :param keep_prob: The probability of dropout. Default set by 1.0 (no drop-out applied)\n",
    "        :param activation_function: The activation function for the output. Default set to None.\n",
    "        :param index: The index of the layer. It is used for naming only.\n",
    "\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('fc_layer_%d' % index):\n",
    "            with tf.name_scope('fc_kernel'):\n",
    "                w_shape = [in_size, out_size]\n",
    "                weight = tf.get_variable(name='fc_kernel_%d' % index, shape=w_shape,\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "                self.weight = weight\n",
    "\n",
    "            with tf.variable_scope('fc_kernel'):\n",
    "                b_shape = [out_size]\n",
    "                bias = tf.get_variable(name='fc_bias_%d' % index, shape=b_shape,\n",
    "                                       initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "                self.bias = bias\n",
    "\n",
    "            cell_out = tf.add(tf.matmul(input_x, weight), bias)\n",
    "            if relu is True:\n",
    "                cell_out = tf.nn.relu(cell_out+bias)\n",
    "            \n",
    "            self.cell_out = cell_out\n",
    "\n",
    "           \n",
    "\n",
    "    def output(self):\n",
    "        return self.cell_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of neural net\n",
    "def LeNet(input_x, input_y, nfilter_1, nfilter_2,nfilter_3, nfilter_4,nfilter_5,nfilter_6,nfilter_7,nfilter_8,\n",
    "        filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8,img_len=32, num_channels=1, l2_norm=0.01, seed=235):\n",
    "    \n",
    "\n",
    "    # conv layer1\n",
    "    conv_layer_0 = conv_layer(input_x=input_x,\n",
    "                              in_channel=num_channels,\n",
    "                              out_channel=nfilter_1,\n",
    "                              kernel_shape=filter_1,\n",
    "                              pooling=True,\n",
    "                              rand_seed=seed,first=True, index=0)\n",
    "    # conv layer2\n",
    "    conv_layer_1 = conv_layer(input_x=conv_layer_0.output(),\n",
    "                              in_channel=nfilter_1,\n",
    "                              out_channel=nfilter_2,\n",
    "                              kernel_shape=filter_2,\n",
    "                              pooling=True,\n",
    "                              rand_seed=seed,first=False,index=1)\n",
    "\n",
    "    # conv layer3\n",
    "    conv_layer_2 = conv_layer(input_x=conv_layer_1.output(),\n",
    "                              in_channel=nfilter_2,\n",
    "                              out_channel=nfilter_3,\n",
    "                              kernel_shape=filter_3,\n",
    "                              pooling=True,\n",
    "                              rand_seed=seed,first=False,index=2)\n",
    "    \n",
    "    dropout_layer_0 = tf.nn.dropout(conv_layer_2.output(), keep_prob=0.9)\n",
    "    \n",
    "    \n",
    "    # flatten\n",
    "    pool_shape = dropout_layer_0.get_shape()\n",
    "    img_vector_length = pool_shape[1].value * pool_shape[2].value * pool_shape[3].value\n",
    "    flatten = tf.reshape(dropout_layer_0, shape=[-1, img_vector_length])\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # fc layer\n",
    "    fc_layer_0 = fc_layer(input_x=flatten,\n",
    "                          in_size=img_vector_length,\n",
    "                          out_size=fclayer1_size,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,\n",
    "                          index=0,\n",
    "                          relu=True)\n",
    "    \n",
    "    dropout_layer_2 = tf.nn.dropout(fc_layer_0.output(), keep_prob=0.5)\n",
    "    \n",
    "    # fc layer\n",
    "    fc_layer_1 = fc_layer(input_x=dropout_layer_2,\n",
    "                          in_size=fclayer1_size,\n",
    "                          out_size=fclayer2_size,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=None,\n",
    "                          index=1,\n",
    "                          relu=False)\n",
    "\n",
    "    dropout_layer_3 = tf.nn.dropout(fc_layer_1.output(), keep_prob=0.9)\n",
    "\n",
    "    \n",
    "       # outputs using softmax\n",
    "    logits_1=fc_layer(input_x=fc_layer_1.output(),\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=2,\n",
    "                          relu=False)\n",
    "    logits_2=fc_layer(input_x=fc_layer_1.output(),\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=3,\n",
    "                          relu=False)\n",
    "    logits_3=fc_layer(input_x=fc_layer_1.output(),\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=4,\n",
    "                          relu=False)\n",
    "    logits_4=fc_layer(input_x=fc_layer_1.output(),\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=5,\n",
    "                          relu=False)\n",
    "    logits_5=fc_layer(input_x=fc_layer_1.output(),\n",
    "                          in_size=fclayer2_size,\n",
    "                          out_size=num_labels,\n",
    "                          rand_seed=seed,\n",
    "                          activation_function=tf.nn.relu,index=6,\n",
    "                          relu=False)\n",
    "    \n",
    "    y_pred = tf.stack([logits_1.output(), logits_2.output(), logits_3.output(), logits_4.output(), logits_5.output()])\n",
    "    y_pred = tf.transpose(tf.argmax(y_pred, axis=2))  \n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "    \n",
    "        loss1 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_1.output(), labels= input_y[:,0]))\n",
    "        loss2 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_2.output(), labels= input_y[:,1]))\n",
    "        loss3 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_3.output(), labels= input_y[:,2]))\n",
    "        loss4 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_4.output(), labels=input_y[:,3]))\n",
    "        loss5 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_5.output(), labels=input_y[:,4]))\n",
    "          \n",
    "        loss = loss1 + loss2 + loss3 + loss4 + loss5 \n",
    "        tf.summary.scalar('loss', loss)\n",
    "        print(\"Iteration done\")\n",
    "\n",
    "    return y_pred,loss\n",
    "\n",
    "\n",
    "\n",
    "def train_step(loss, learning_rate=1e-3):\n",
    "    \n",
    "    #Optimizer function\n",
    "    with tf.name_scope('train_step'):\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate=1e-3\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        step = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    return step\n",
    "\n",
    "def evaluate(predictions, labels):\n",
    "    #Accuracy calculation\n",
    "    with tf.name_scope('accuracy'):\n",
    "            correct_prediction = tf.equal(predictions, labels)\n",
    "            correct_prediction=tf.cast(correct_prediction, tf.float32)\n",
    "            correct_prediction=tf.reduce_min(correct_prediction,1)\n",
    "            acc=tf.reduce_mean(correct_prediction)\n",
    "            tf.summary.scalar('accuracy', acc)\n",
    "            acc=acc*100\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training function for the LeNet model\n",
    "def training(X_train, y_train, X_val, y_val,X_test,y_test, nfilter_1, nfilter_2,nfilter_3, nfilter_4,nfilter_5,nfilter_6,nfilter_7,nfilter_8,filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8,img_len=32, num_channels=1, l2_norm=0.01, \n",
    "             seed=235,\n",
    "             learning_rate=1e-2,\n",
    "             epoch=20,\n",
    "             batch_size=245,\n",
    "             verbose=False,\n",
    "             pre_trained_model=None):\n",
    "    best_acc_li=[]\n",
    "    all_acc=[]\n",
    "    \n",
    "\n",
    "    \n",
    "    with tf.name_scope('inputs'):\n",
    "        xs = tf.placeholder(shape=[None, 54, 54, 3], dtype=tf.float32)\n",
    "        ys = tf.placeholder(shape=[None,5 ], dtype=tf.int64)\n",
    "       \n",
    "\n",
    "    output, loss = LeNet(xs, ys, nfilter_1, nfilter_2,nfilter_3, nfilter_4,nfilter_5,nfilter_6,nfilter_7,nfilter_8,\n",
    "        filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8, img_len=54, num_channels=3, l2_norm=0.01, seed=235)\n",
    "    print(\"Done LeNet training\")\n",
    "    print(output)\n",
    "    iters = int(X_train.shape[0] / batch_size)\n",
    "    print('number of batches for training: {}'.format(iters))\n",
    "\n",
    "    step = train_step(loss)\n",
    "    eve = evaluate(output,ys)\n",
    "\n",
    "    iter_total = 0\n",
    "    best_acc = 0\n",
    "    cur_model_name = 'lenet_{}'.format(int(time.time()))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        merge = tf.summary.merge_all()\n",
    "\n",
    "        writer = tf.summary.FileWriter(\"log/{}\".format(cur_model_name), sess.graph)\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "      \n",
    "        if pre_trained_model is not None:\n",
    "            try:\n",
    "                print(\"Load the model from: {}\".format(pre_trained_model))\n",
    "                saver.restore(sess, 'model/{}'.format(pre_trained_model))\n",
    "            except Exception:\n",
    "                print(\"Load model Failed!\")\n",
    "                pass\n",
    "\n",
    "        for epc in range(epoch):\n",
    "            print(\"epoch {} \".format(epc + 1))\n",
    "\n",
    "            for itr in range(iters):\n",
    "                iter_total += 1\n",
    "\n",
    "                training_batch_x = X_train[itr * batch_size: (1 + itr) * batch_size]\n",
    "                training_batch_y = y_train[itr * batch_size: (1 + itr) * batch_size]\n",
    "\n",
    "                _, cur_loss = sess.run([step, loss], feed_dict={xs: training_batch_x, ys: training_batch_y})\n",
    "                \n",
    "                \n",
    "                if iter_total % 500 == 0:\n",
    "                    # do validation\n",
    "                    \n",
    "                    valid_acc, merge_result = sess.run([eve, merge], feed_dict={xs: X_val, ys: y_val})\n",
    "                    if verbose:\n",
    "                        print('{}/{} loss: {} validation accuracy : {}%'.format(\n",
    "                            batch_size * (itr + 1),\n",
    "                            X_train.shape[0],\n",
    "                            cur_loss,\n",
    "                            valid_acc))\n",
    "                    all_acc.append(valid_acc)\n",
    "                    # save the merge result summary\n",
    "                    writer.add_summary(merge_result, iter_total)\n",
    "\n",
    "                    # when achieve the best validation accuracy, we store the model paramters\n",
    "                    if valid_acc > best_acc:\n",
    "                        print('Best validation accuracy! iteration:{} accuracy: {}%'.format(iter_total, valid_acc))\n",
    "                        best_acc = valid_acc\n",
    "                        best_acc_li.append(best_acc)\n",
    "                        saver.save(sess, 'model/{}'.format(cur_model_name))\n",
    "                        \n",
    "                    test_acc = sess.run(eve, feed_dict={xs: X_test, ys: y_test})\n",
    "                    print('Test Accuracy : {}'.format(test_acc))\n",
    "        \n",
    "        test_acc = sess.run(eve, feed_dict={xs: X_test, ys: y_test})\n",
    "        print('Test Accuracy : {}'.format(test_acc))\n",
    "    \n",
    "    print(\"Traning ends. The best valid accuracy is {}. Model named {}.\".format(best_acc, cur_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional layer units\n",
    "filter_1 = filter_2 = filter_3 = filter_4=filter_5=filter_6=filter_7=filter_8 = 5        \n",
    "nfilter_1 = 48\n",
    "nfilter_2 = 64                 \n",
    "nfilter_3 = 128\n",
    "nfilter_4 = 160   \n",
    "nfilter_5=nfilter_6=nfilter_7=nfilter_8=192\n",
    "# Fully connected layer units\n",
    "fclayer1_size = fclayer2_size = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 48)\n",
      "(?, 4, 4, 64)\n",
      "(?, 1, 1, 128)\n",
      "WARNING:tensorflow:From <ipython-input-31-b096f59096fe>:152: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "(?, 5)\n",
      "(?, 11)\n",
      "(?,)\n",
      "Iteration done\n",
      "Done LeNet training\n",
      "Tensor(\"transpose:0\", shape=(?, 5), dtype=int64)\n",
      "number of batches for training: 334\n",
      "Tensor(\"accuracy/Min:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"accuracy/mul:0\", shape=(), dtype=float32)\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "7.6\n",
      "Best validation accuracy! iteration:500 accuracy: 7.599999904632568%\n",
      "Test Accuracy : 7.636975288391113\n",
      "epoch 3 \n",
      "19.175\n",
      "Best validation accuracy! iteration:1000 accuracy: 19.17500114440918%\n",
      "Test Accuracy : 17.883378982543945\n",
      "epoch 4 \n",
      "epoch 5 \n",
      "27.15\n",
      "Best validation accuracy! iteration:1500 accuracy: 27.149999618530273%\n",
      "Test Accuracy : 22.474748611450195\n",
      "epoch 6 \n",
      "36.125\n",
      "Best validation accuracy! iteration:2000 accuracy: 36.125%\n",
      "Test Accuracy : 29.95102310180664\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "40.75\n",
      "Best validation accuracy! iteration:2500 accuracy: 40.75%\n",
      "Test Accuracy : 32.529842376708984\n",
      "epoch 9 \n",
      "45.25\n",
      "Best validation accuracy! iteration:3000 accuracy: 45.25%\n",
      "Test Accuracy : 34.37404251098633\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "48.325\n",
      "Best validation accuracy! iteration:3500 accuracy: 48.32500076293945%\n",
      "Test Accuracy : 34.94796371459961\n",
      "epoch 12 \n",
      "50.8\n",
      "Best validation accuracy! iteration:4000 accuracy: 50.80000305175781%\n",
      "Test Accuracy : 35.70553970336914\n",
      "epoch 13 \n",
      "epoch 14 \n",
      "53.875\n",
      "Best validation accuracy! iteration:4500 accuracy: 53.875%\n",
      "Test Accuracy : 38.10835647583008\n",
      "epoch 15 \n",
      "55.8\n",
      "Best validation accuracy! iteration:5000 accuracy: 55.80000305175781%\n",
      "Test Accuracy : 37.09060287475586\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "61.275\n",
      "Best validation accuracy! iteration:5500 accuracy: 61.27499771118164%\n",
      "Test Accuracy : 39.164371490478516\n",
      "epoch 18 \n",
      "62.525\n",
      "Best validation accuracy! iteration:6000 accuracy: 62.52499771118164%\n",
      "Test Accuracy : 39.57759475708008\n",
      "epoch 19 \n",
      "epoch 20 \n",
      "62.775\n",
      "Best validation accuracy! iteration:6500 accuracy: 62.77499771118164%\n",
      "Test Accuracy : 39.707679748535156\n",
      "epoch 21 \n",
      "65.5\n",
      "Best validation accuracy! iteration:7000 accuracy: 65.5%\n",
      "Test Accuracy : 39.49341583251953\n",
      "epoch 22 \n",
      "epoch 23 \n",
      "64.325\n",
      "Test Accuracy : 38.70523452758789\n",
      "epoch 24 \n",
      "66.125\n",
      "Best validation accuracy! iteration:8000 accuracy: 66.125%\n",
      "Test Accuracy : 38.835323333740234\n",
      "epoch 25 \n",
      "epoch 26 \n",
      "67.55\n",
      "Best validation accuracy! iteration:8500 accuracy: 67.54999542236328%\n",
      "Test Accuracy : 39.21028518676758\n",
      "epoch 27 \n",
      "66.7\n",
      "Test Accuracy : 37.71809005737305\n",
      "epoch 28 \n",
      "epoch 29 \n",
      "68.2\n",
      "Best validation accuracy! iteration:9500 accuracy: 68.19999694824219%\n",
      "Test Accuracy : 38.94245529174805\n",
      "epoch 30 \n",
      "69.9\n",
      "Best validation accuracy! iteration:10000 accuracy: 69.9000015258789%\n",
      "Test Accuracy : 38.35322952270508\n",
      "epoch 31 \n",
      "epoch 32 \n",
      "72.45\n",
      "Best validation accuracy! iteration:10500 accuracy: 72.44999694824219%\n",
      "Test Accuracy : 39.48576736450195\n",
      "epoch 33 \n",
      "72.875\n",
      "Best validation accuracy! iteration:11000 accuracy: 72.875%\n",
      "Test Accuracy : 38.307315826416016\n",
      "epoch 34 \n",
      "epoch 35 \n",
      "73.7\n",
      "Best validation accuracy! iteration:11500 accuracy: 73.69999694824219%\n",
      "Test Accuracy : 39.08784866333008\n",
      "epoch 36 \n",
      "75.55\n",
      "Best validation accuracy! iteration:12000 accuracy: 75.55000305175781%\n",
      "Test Accuracy : 38.2690544128418\n",
      "epoch 37 \n",
      "epoch 38 \n",
      "75.1\n",
      "Test Accuracy : 39.21793746948242\n",
      "epoch 39 \n",
      "76.55\n",
      "Best validation accuracy! iteration:13000 accuracy: 76.55000305175781%\n",
      "Test Accuracy : 38.94245529174805\n",
      "epoch 40 \n",
      "epoch 41 \n",
      "76.6\n",
      "Best validation accuracy! iteration:13500 accuracy: 76.5999984741211%\n",
      "Test Accuracy : 38.59810256958008\n",
      "epoch 42 \n",
      "75.75\n",
      "Test Accuracy : 39.03428268432617\n",
      "epoch 43 \n",
      "epoch 44 \n",
      "77.125\n",
      "Best validation accuracy! iteration:14500 accuracy: 77.125%\n",
      "Test Accuracy : 37.90939712524414\n",
      "epoch 45 \n",
      "76.975\n",
      "Test Accuracy : 38.62105941772461\n",
      "epoch 46 \n",
      "epoch 47 \n",
      "78.85\n",
      "Best validation accuracy! iteration:15500 accuracy: 78.8499984741211%\n",
      "Test Accuracy : 38.3226203918457\n",
      "epoch 48 \n",
      "80.4\n",
      "Best validation accuracy! iteration:16000 accuracy: 80.4000015258789%\n",
      "Test Accuracy : 38.62105941772461\n",
      "epoch 49 \n",
      "epoch 50 \n",
      "79.575\n",
      "Test Accuracy : 38.60575485229492\n",
      "epoch 51 \n",
      "81.525\n",
      "Best validation accuracy! iteration:17000 accuracy: 81.5250015258789%\n",
      "Test Accuracy : 38.21548843383789\n",
      "epoch 52 \n",
      "epoch 53 \n",
      "80.3\n",
      "Test Accuracy : 38.2690544128418\n",
      "epoch 54 \n",
      "81.6\n",
      "Best validation accuracy! iteration:18000 accuracy: 81.5999984741211%\n",
      "Test Accuracy : 38.47566604614258\n",
      "epoch 55 \n",
      "epoch 56 \n",
      "81.325\n",
      "Test Accuracy : 37.9017448425293\n",
      "epoch 57 \n",
      "82.0\n",
      "Best validation accuracy! iteration:19000 accuracy: 82.0%\n",
      "Test Accuracy : 37.94765853881836\n",
      "epoch 58 \n",
      "epoch 59 \n",
      "82.425\n",
      "Best validation accuracy! iteration:19500 accuracy: 82.42499542236328%\n",
      "Test Accuracy : 37.84817886352539\n",
      "epoch 60 \n",
      "80.8\n",
      "Test Accuracy : 37.7104377746582\n",
      "epoch 61 \n",
      "epoch 62 \n",
      "84.75\n",
      "Best validation accuracy! iteration:20500 accuracy: 84.75%\n",
      "Test Accuracy : 38.23844528198242\n",
      "epoch 63 \n",
      "84.3\n",
      "Test Accuracy : 38.406795501708984\n",
      "epoch 64 \n",
      "epoch 65 \n",
      "84.65\n",
      "Test Accuracy : 38.468013763427734\n",
      "epoch 66 \n",
      "84.25\n",
      "Test Accuracy : 38.49862289428711\n",
      "epoch 67 \n",
      "epoch 68 \n",
      "84.95\n",
      "Best validation accuracy! iteration:22500 accuracy: 84.94999694824219%\n",
      "Test Accuracy : 37.96296310424805\n",
      "epoch 69 \n",
      "84.875\n",
      "Test Accuracy : 37.633914947509766\n",
      "epoch 70 \n",
      "epoch 71 \n",
      "85.2\n",
      "Best validation accuracy! iteration:23500 accuracy: 85.19999694824219%\n",
      "Test Accuracy : 38.284358978271484\n",
      "epoch 72 \n",
      "84.825\n",
      "Test Accuracy : 37.76400375366211\n",
      "epoch 73 \n",
      "epoch 74 \n",
      "84.35\n",
      "Test Accuracy : 37.74104690551758\n",
      "epoch 75 \n",
      "85.3\n",
      "Best validation accuracy! iteration:25000 accuracy: 85.29999542236328%\n",
      "Test Accuracy : 38.29966354370117\n",
      "epoch 76 \n",
      "epoch 77 \n",
      "86.2\n",
      "Best validation accuracy! iteration:25500 accuracy: 86.19999694824219%\n",
      "Test Accuracy : 38.65932083129883\n",
      "epoch 78 \n",
      "86.675\n",
      "Best validation accuracy! iteration:26000 accuracy: 86.67500305175781%\n",
      "Test Accuracy : 38.246097564697266\n",
      "epoch 79 \n",
      "epoch 80 \n",
      "86.925\n",
      "Best validation accuracy! iteration:26500 accuracy: 86.92500305175781%\n",
      "Test Accuracy : 38.11600875854492\n",
      "Test Accuracy : 38.368534088134766\n",
      "Traning ends. The best valid accuracy is 86.92500305175781. Model named lenet_1513537576.\n"
     ]
    }
   ],
   "source": [
    "# Call train function\n",
    "temp=time.time()\n",
    "training(X_train, y_train, X_val, y_val, X_test,y_test, nfilter_1, nfilter_2,nfilter_3, nfilter_4,nfilter_5,nfilter_6,nfilter_7,nfilter_8,filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8,img_len=54, num_channels=3, l2_norm=0.01, \n",
    "             seed=235,\n",
    "             learning_rate=1e-3,\n",
    "             epoch=80,\n",
    "             batch_size=100,\n",
    "             verbose=False,\n",
    "             pre_trained_model=None)\n",
    "temp_1=time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 24)\n",
      "(?, 4, 4, 48)\n",
      "(?, 1, 1, 64)\n",
      "(?, 1, 1, 160)\n",
      "(?, 400)\n",
      "WARNING:tensorflow:From <ipython-input-15-d498546d9b09>:132: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "(?, 5)\n",
      "(?, 11)\n",
      "(?,)\n",
      "Iteration done\n",
      "Done LeNet training\n",
      "Tensor(\"transpose:0\", shape=(?, 5), dtype=int64)\n",
      "number of batches for training: 554\n",
      "Tensor(\"accuracy/Min:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"accuracy/mul:0\", shape=(), dtype=float32)\n",
      "epoch 1 \n",
      "0.933333\n",
      "Best validation accuracy! iteration:100 accuracy: 0.9333332777023315%\n",
      "1.56667\n",
      "Best validation accuracy! iteration:200 accuracy: 1.5666667222976685%\n",
      "2.11667\n",
      "Best validation accuracy! iteration:300 accuracy: 2.116666793823242%\n",
      "2.01667\n",
      "3.35\n",
      "Best validation accuracy! iteration:500 accuracy: 3.3500001430511475%\n",
      "epoch 2 \n",
      "4.31667\n",
      "Best validation accuracy! iteration:600 accuracy: 4.316666603088379%\n",
      "4.58333\n",
      "Best validation accuracy! iteration:700 accuracy: 4.583333492279053%\n",
      "5.05\n",
      "Best validation accuracy! iteration:800 accuracy: 5.050000190734863%\n",
      "6.83333\n",
      "Best validation accuracy! iteration:900 accuracy: 6.833333492279053%\n",
      "7.68333\n",
      "Best validation accuracy! iteration:1000 accuracy: 7.683332920074463%\n",
      "8.36667\n",
      "Best validation accuracy! iteration:1100 accuracy: 8.366666793823242%\n",
      "epoch 3 \n",
      "9.65\n",
      "Best validation accuracy! iteration:1200 accuracy: 9.65000057220459%\n",
      "10.2667\n",
      "Best validation accuracy! iteration:1300 accuracy: 10.266666412353516%\n",
      "12.0333\n",
      "Best validation accuracy! iteration:1400 accuracy: 12.033333778381348%\n",
      "13.7\n",
      "Best validation accuracy! iteration:1500 accuracy: 13.699999809265137%\n",
      "14.5\n",
      "Best validation accuracy! iteration:1600 accuracy: 14.5%\n",
      "epoch 4 \n",
      "16.2333\n",
      "Best validation accuracy! iteration:1700 accuracy: 16.233333587646484%\n",
      "16.1333\n",
      "16.3167\n",
      "Best validation accuracy! iteration:1900 accuracy: 16.316667556762695%\n",
      "16.8667\n",
      "Best validation accuracy! iteration:2000 accuracy: 16.866666793823242%\n",
      "20.1\n",
      "Best validation accuracy! iteration:2100 accuracy: 20.100000381469727%\n",
      "20.6\n",
      "Best validation accuracy! iteration:2200 accuracy: 20.600000381469727%\n",
      "epoch 5 \n",
      "22.5333\n",
      "Best validation accuracy! iteration:2300 accuracy: 22.53333282470703%\n",
      "24.95\n",
      "Best validation accuracy! iteration:2400 accuracy: 24.950000762939453%\n",
      "24.1333\n",
      "23.4167\n",
      "24.25\n",
      "epoch 6 \n",
      "27.0333\n",
      "Best validation accuracy! iteration:2800 accuracy: 27.03333282470703%\n",
      "27.75\n",
      "Best validation accuracy! iteration:2900 accuracy: 27.75%\n",
      "27.65\n",
      "27.6833\n",
      "29.6667\n",
      "Best validation accuracy! iteration:3200 accuracy: 29.66666603088379%\n",
      "29.5833\n",
      "epoch 7 \n",
      "31.1167\n",
      "Best validation accuracy! iteration:3400 accuracy: 31.116666793823242%\n",
      "32.1333\n",
      "Best validation accuracy! iteration:3500 accuracy: 32.133331298828125%\n",
      "30.1667\n",
      "31.65\n",
      "33.1333\n",
      "Best validation accuracy! iteration:3800 accuracy: 33.13333511352539%\n",
      "epoch 8 \n",
      "32.55\n",
      "34.2667\n",
      "Best validation accuracy! iteration:4000 accuracy: 34.266666412353516%\n",
      "35.0833\n",
      "Best validation accuracy! iteration:4100 accuracy: 35.08333206176758%\n",
      "35.4\n",
      "Best validation accuracy! iteration:4200 accuracy: 35.400001525878906%\n",
      "34.9333\n",
      "33.45\n",
      "epoch 9 \n",
      "33.2\n",
      "36.35\n",
      "Best validation accuracy! iteration:4600 accuracy: 36.349998474121094%\n",
      "36.6167\n",
      "Best validation accuracy! iteration:4700 accuracy: 36.616668701171875%\n",
      "35.4833\n",
      "35.9667\n",
      "epoch 10 \n",
      "34.7\n",
      "37.6167\n",
      "Best validation accuracy! iteration:5100 accuracy: 37.616668701171875%\n",
      "37.8\n",
      "Best validation accuracy! iteration:5200 accuracy: 37.79999923706055%\n",
      "37.45\n",
      "39.45\n",
      "Best validation accuracy! iteration:5400 accuracy: 39.44999694824219%\n",
      "39.2833\n",
      "epoch 11 \n",
      "39.0\n",
      "39.1333\n",
      "38.7\n",
      "39.65\n",
      "Best validation accuracy! iteration:5900 accuracy: 39.64999771118164%\n",
      "38.5167\n",
      "epoch 12 \n",
      "40.3167\n",
      "Best validation accuracy! iteration:6100 accuracy: 40.31666946411133%\n",
      "40.5667\n",
      "Best validation accuracy! iteration:6200 accuracy: 40.56666946411133%\n",
      "40.3\n",
      "41.45\n",
      "Best validation accuracy! iteration:6400 accuracy: 41.45000076293945%\n",
      "44.05\n",
      "Best validation accuracy! iteration:6500 accuracy: 44.04999923706055%\n",
      "41.35\n",
      "epoch 13 \n",
      "41.6833\n",
      "39.8833\n",
      "38.75\n",
      "40.3667\n",
      "39.75\n",
      "42.0167\n",
      "epoch 14 \n",
      "38.9\n",
      "41.8667\n",
      "44.7833\n",
      "Best validation accuracy! iteration:7500 accuracy: 44.78333282470703%\n",
      "43.2\n",
      "42.2333\n",
      "epoch 15 \n",
      "44.6167\n",
      "43.0833\n",
      "44.6333\n",
      "44.1833\n",
      "44.75\n",
      "44.2333\n",
      "epoch 16 \n",
      "43.8833\n",
      "44.7\n",
      "43.5\n",
      "48.25\n",
      "Best validation accuracy! iteration:8700 accuracy: 48.25%\n",
      "44.95\n",
      "epoch 17 \n",
      "45.7167\n",
      "45.1\n",
      "45.1\n",
      "43.9833\n",
      "46.4667\n",
      "46.2667\n",
      "epoch 18 \n",
      "47.6667\n",
      "48.5167\n",
      "Best validation accuracy! iteration:9600 accuracy: 48.516666412353516%\n",
      "49.5167\n",
      "Best validation accuracy! iteration:9700 accuracy: 49.516666412353516%\n",
      "44.7167\n",
      "48.5833\n",
      "epoch 19 \n",
      "48.9333\n",
      "47.4333\n",
      "45.5667\n",
      "48.7167\n",
      "45.9833\n",
      "48.6\n",
      "epoch 20 \n",
      "47.8667\n",
      "46.8833\n",
      "49.2667\n",
      "48.25\n",
      "49.15\n",
      "epoch 21 \n",
      "49.2\n",
      "50.75\n",
      "Best validation accuracy! iteration:11200 accuracy: 50.75%\n",
      "50.25\n",
      "48.7167\n",
      "50.5833\n",
      "48.9333\n",
      "epoch 22 \n",
      "51.4333\n",
      "Best validation accuracy! iteration:11700 accuracy: 51.43333053588867%\n",
      "49.8167\n",
      "51.35\n",
      "51.3167\n",
      "50.1833\n",
      "epoch 23 \n",
      "49.7\n",
      "47.6667\n",
      "51.1833\n",
      "51.9167\n",
      "Best validation accuracy! iteration:12500 accuracy: 51.916664123535156%\n",
      "51.95\n",
      "Best validation accuracy! iteration:12600 accuracy: 51.95000076293945%\n",
      "49.0833\n",
      "epoch 24 \n",
      "51.6667\n",
      "52.0\n",
      "Best validation accuracy! iteration:12900 accuracy: 52.0%\n",
      "49.9167\n",
      "51.8667\n",
      "51.1333\n",
      "epoch 25 \n",
      "53.3833\n",
      "Best validation accuracy! iteration:13300 accuracy: 53.383331298828125%\n",
      "51.95\n",
      "51.6\n",
      "52.0833\n",
      "51.9667\n",
      "45.1\n",
      "epoch 26 \n",
      "52.2167\n",
      "50.9667\n",
      "54.5667\n",
      "Best validation accuracy! iteration:14100 accuracy: 54.56666946411133%\n",
      "52.5167\n",
      "51.8167\n",
      "54.3833\n",
      "epoch 27 \n",
      "52.95\n",
      "53.15\n",
      "52.6333\n",
      "53.0333\n",
      "52.95\n",
      "epoch 28 \n",
      "54.25\n",
      "54.4167\n",
      "53.4167\n",
      "54.4667\n",
      "53.5667\n",
      "53.5333\n",
      "epoch 29 \n",
      "53.1833\n",
      "53.7167\n",
      "54.7\n",
      "Best validation accuracy! iteration:15800 accuracy: 54.70000076293945%\n",
      "54.1167\n",
      "54.3\n",
      "epoch 30 \n",
      "53.5833\n",
      "52.0833\n",
      "53.9833\n",
      "53.2833\n",
      "54.2833\n",
      "54.9833\n",
      "Best validation accuracy! iteration:16600 accuracy: 54.98333740234375%\n",
      "epoch 31 \n",
      "54.0333\n",
      "54.9833\n",
      "54.7667\n",
      "54.9833\n",
      "55.0833\n",
      "Best validation accuracy! iteration:17100 accuracy: 55.083335876464844%\n",
      "epoch 32 \n",
      "55.25\n",
      "Best validation accuracy! iteration:17200 accuracy: 55.25%\n",
      "55.8333\n",
      "Best validation accuracy! iteration:17300 accuracy: 55.83333206176758%\n",
      "55.9833\n",
      "Best validation accuracy! iteration:17400 accuracy: 55.983333587646484%\n",
      "54.7\n",
      "52.8\n",
      "56.7\n",
      "Best validation accuracy! iteration:17700 accuracy: 56.69999694824219%\n",
      "epoch 33 \n",
      "56.1\n",
      "56.2333\n",
      "56.0167\n",
      "53.9167\n",
      "56.6167\n",
      "epoch 34 \n",
      "55.4667\n",
      "56.5167\n",
      "55.3167\n",
      "56.1833\n",
      "55.0\n",
      "54.9667\n",
      "epoch 35 \n",
      "56.4333\n",
      "55.3333\n",
      "56.3333\n",
      "56.4833\n",
      "55.4667\n",
      "epoch 36 \n",
      "57.1667\n",
      "Best validation accuracy! iteration:19400 accuracy: 57.166664123535156%\n",
      "54.7833\n",
      "56.5833\n",
      "56.2667\n",
      "55.4333\n",
      "55.2333\n",
      "epoch 37 \n",
      "56.0333\n",
      "55.3\n",
      "57.0833\n",
      "55.3\n",
      "56.7333\n",
      "epoch 38 \n",
      "56.2\n",
      "56.4833\n",
      "56.7333\n",
      "57.45\n",
      "Best validation accuracy! iteration:20800 accuracy: 57.45000076293945%\n",
      "56.4167\n",
      "56.25\n",
      "epoch 39 \n",
      "57.8\n",
      "Best validation accuracy! iteration:21100 accuracy: 57.79999923706055%\n",
      "55.5333\n",
      "57.4833\n",
      "55.85\n",
      "58.0167\n",
      "Best validation accuracy! iteration:21500 accuracy: 58.01666259765625%\n",
      "55.8167\n",
      "epoch 40 \n",
      "57.7333\n",
      "53.2833\n",
      "58.0\n",
      "57.5\n",
      "57.2167\n",
      "epoch 41 \n",
      "55.1\n",
      "58.5667\n",
      "Best validation accuracy! iteration:22300 accuracy: 58.56666564941406%\n",
      "56.2\n",
      "57.8\n",
      "56.7167\n",
      "56.8167\n",
      "epoch 42 \n",
      "57.9667\n",
      "58.65\n",
      "Best validation accuracy! iteration:22900 accuracy: 58.64999771118164%\n",
      "58.0833\n",
      "58.8833\n",
      "Best validation accuracy! iteration:23100 accuracy: 58.883331298828125%\n",
      "57.4333\n",
      "epoch 43 \n",
      "57.4667\n",
      "57.4333\n",
      "58.6167\n",
      "57.9667\n",
      "55.65\n",
      "57.1667\n",
      "epoch 44 \n",
      "56.6333\n",
      "57.5667\n",
      "57.3167\n",
      "57.2833\n",
      "58.0167\n",
      "epoch 45 \n",
      "58.1833\n",
      "57.35\n",
      "57.9833\n",
      "58.3667\n",
      "59.75\n",
      "Best validation accuracy! iteration:24800 accuracy: 59.750003814697266%\n",
      "57.2667\n",
      "epoch 46 \n",
      "58.9\n",
      "58.9333\n",
      "58.8333\n",
      "58.8167\n",
      "58.5667\n",
      "epoch 47 \n",
      "57.2167\n",
      "58.4167\n",
      "58.2333\n",
      "57.7\n",
      "59.65\n",
      "58.55\n",
      "epoch 48 \n",
      "58.55\n",
      "59.4167\n",
      "58.95\n",
      "58.1667\n",
      "58.2667\n",
      "epoch 49 \n",
      "59.6\n",
      "56.1\n",
      "58.1333\n",
      "59.2167\n",
      "57.9333\n",
      "56.7\n",
      "epoch 50 \n",
      "58.8333\n",
      "57.2667\n",
      "58.0667\n",
      "59.3333\n",
      "59.4833\n",
      "59.6333\n",
      "epoch 51 \n",
      "59.55\n",
      "59.45\n",
      "59.2\n",
      "58.75\n",
      "59.6\n",
      "epoch 52 \n",
      "58.9833\n",
      "59.85\n",
      "Best validation accuracy! iteration:28400 accuracy: 59.85000228881836%\n",
      "58.8833\n",
      "58.5333\n",
      "59.4833\n",
      "58.8\n",
      "epoch 53 \n",
      "59.6833\n",
      "58.4667\n",
      "57.8\n",
      "59.3333\n",
      "60.1\n",
      "Best validation accuracy! iteration:29300 accuracy: 60.10000228881836%\n",
      "epoch 54 \n",
      "60.5333\n",
      "Best validation accuracy! iteration:29400 accuracy: 60.53333282470703%\n",
      "59.7\n",
      "59.1\n",
      "60.5167\n",
      "60.1333\n",
      "57.5333\n",
      "epoch 55 \n",
      "59.3\n",
      "60.3333\n",
      "61.7167\n",
      "Best validation accuracy! iteration:30200 accuracy: 61.7166633605957%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.05\n",
      "59.55\n",
      "epoch 56 \n",
      "59.6167\n",
      "60.4167\n",
      "60.75\n",
      "59.9667\n",
      "60.6833\n",
      "59.3333\n",
      "epoch 57 \n",
      "59.8\n",
      "60.4667\n",
      "59.25\n",
      "60.3\n",
      "60.2\n",
      "epoch 58 \n",
      "61.5\n",
      "60.6833\n",
      "61.0667\n",
      "60.9667\n",
      "61.2\n",
      "61.5167\n",
      "epoch 59 \n",
      "60.55\n",
      "60.0333\n",
      "61.1333\n",
      "60.1833\n",
      "61.4167\n",
      "epoch 60 \n",
      "58.3667\n",
      "59.8667\n",
      "60.0\n",
      "60.7167\n",
      "58.85\n",
      "61.3167\n",
      "Traning ends. The best valid accuracy is 61.7166633605957. Model named lenet_1513454425.\n"
     ]
    }
   ],
   "source": [
    "#Call train function with higher learning rate\n",
    "temp=time.time()\n",
    "training(X_train, y_train, X_val, y_val, nfilter_1, nfilter_2,nfilter_3, nfilter_4,nfilter_5,nfilter_6,nfilter_7,nfilter_8,filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8,img_len=54, num_channels=1, l2_norm=0.01, \n",
    "             seed=235,\n",
    "             learning_rate=1e-1,\n",
    "             epoch=60,\n",
    "             batch_size=100,\n",
    "             verbose=False,\n",
    "             pre_trained_model=None)\n",
    "temp_1=time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5599.422572851181"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(temp_1-temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
